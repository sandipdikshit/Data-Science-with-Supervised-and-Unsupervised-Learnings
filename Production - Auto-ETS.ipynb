{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b5e5d22",
   "metadata": {},
   "source": [
    "### Aim - To study the properties of 'Production' time series & its forecastability for the next two quarters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6c87e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clinic_id_to_name = {'64f0b7632f3bdb0027dad42d': 'Gallatin Valley Pediatric Dentistry',\n",
    "#     '6425169370931f001beaa4cd': 'Epic Orthodontics',\n",
    "#     '64250f34097f4a001a08a7c3': 'Camp Smile Pediatric Dentistry',\n",
    "#     '64312aa11daa0c00265192ff': 'Rallis & Bonilla Orthodontics',\n",
    "#     '643f8894728f4b0026fbcf83': 'Lincoln Pediatric Dentistry-N',\n",
    "#     '645b4ccda400ef00260afdf0': 'Kottemann Orthodontics, PLLC',\n",
    "#     '62adfa719123bc3764868b7f': 'Commonwealth Dental Clinic',\n",
    "#     '62adfb600d661bd231013b31': 'Blue Ridge Dental Group, Cbrg, PC',\n",
    "#     '62adf7883ad607ffbb79d6e8': 'Valley Dental',\n",
    "#     '62adf4dcf38e0d017b277dd0': 'Blue Ridge Dental Group Smith Mountain Lake',\n",
    "#     '62c0d06f6a71b71f07d1c326': 'Blue Ridge Dental Group Salem Office',\n",
    "#     '60dfe27720beb16201b91245': 'Triangle Family Dentistry',\n",
    "#     '6456c0a6acf79c5e6d0e8e66': 'ProGrin Dental and iGrin Pediatric Dentistry',\n",
    "#     '64290e515130aa001e9788ea': 'Sonrava, Inc. (Original)'}\n",
    "# dataset['clinic_id'] = dataset['clinic_id'].map(clinic_id_to_name)\n",
    "# dataset.rename(columns={'clinic_id': 'Clinic_Name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3da0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, tensorflow as tf, plotly.graph_objects as go, plotly.express as px, matplotlib.pyplot as plt\n",
    "import pandas_datareader,warnings,seaborn as sns,numpy as np,math,datetime as dt,pmdarima,tensorflow as tf,holoviews as hv\n",
    "import hvplot.pandas\n",
    "from matplotlib.dates import WeekdayLocator, DateFormatter\n",
    "from IPython.display import display, HTML\n",
    "from sklearn import preprocessing, metrics\n",
    "from pandas_datareader.data import DataReader\n",
    "from itertools import cycle\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Import statsmodels\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder,LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, \n",
    "    roc_auc_score, \n",
    "    roc_curve, \n",
    "    auc, \n",
    "    classification_report, \n",
    "    mean_squared_error, \n",
    "    mean_absolute_error, \n",
    "    explained_variance_score, \n",
    "    r2_score, \n",
    "    mean_poisson_deviance, \n",
    "    mean_gamma_deviance, \n",
    "    accuracy_score)\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LSTM, GRU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Import scipy\n",
    "from scipy.stats import boxcox\n",
    "from scipy import stats\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "# Display\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "pd.set_option(\"display.max_rows\", 1000)\n",
    "pd.set_option(\"display.max_columns\", 1000)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518e0cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('OneDrive - DENTINE INFORMATICS LLP/Desktop/Ledgers.csv', parse_dates = True)\n",
    "dataset.ledger_date = pd.to_datetime(dataset.ledger_date)\n",
    "dataset = dataset[dataset.category == \"Production\"]\n",
    "data = dataset.filter(['ledger_date', 'debit_src'])\n",
    "data.set_index('ledger_date', inplace = True)\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5acfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prod = data.pivot_table(index='ledger_date', columns='Clinic_Name', values='debit_src', aggfunc='sum')\n",
    "# prod.reset_index(inplace=True)\n",
    "# prod.fillna(0, inplace=True)\n",
    "# prod.columns.name = None\n",
    "# prod.set_index('ledger_date', inplace = True)\n",
    "\n",
    "# provider = dataset.pivot_table(index='ledger_date', columns='provider_name', values='debit_src', aggfunc='sum')\n",
    "# provider.reset_index(inplace=True)\n",
    "# provider.fillna(0, inplace=True)\n",
    "# provider.columns.name = None\n",
    "# provider.set_index('ledger_date', inplace = True)\n",
    "\n",
    "# proc = dataset.pivot_table(index='ledger_date', columns='proc_code', values='debit_src', aggfunc='sum')\n",
    "# proc.reset_index(inplace=True)\n",
    "# proc.fillna(0, inplace=True)\n",
    "# proc.columns.name = None\n",
    "# proc.set_index('ledger_date', inplace = True)\n",
    "\n",
    "# pat = dataset.pivot_table(index='ledger_date', columns='Is_NewPatient', values='debit_src', aggfunc='sum')\n",
    "# pat.reset_index(inplace=True)\n",
    "# pat.fillna(0, inplace=True)\n",
    "# pat.columns.name = None\n",
    "# pat.set_index('ledger_date', inplace = True)\n",
    "\n",
    "# clinic_returns = prod.pct_change()\n",
    "# proc_returns = proc.pct_change()\n",
    "# pat_returns = pat.pct_change()\n",
    "# provider_returns = provider.pct_change()\n",
    "\n",
    "# num_clinics = len(prod.columns)\n",
    "# num_rows = math.ceil(num_clinics / 2)  # Use 2 columns per row\n",
    "# fig, axes = plt.subplots(nrows=num_rows, ncols=2, figsize=(18, 3 * num_rows))\n",
    "\n",
    "# # Plot daily returns for each clinic\n",
    "# for i, clinic_name in enumerate(prod.columns):\n",
    "#     ax_row = i // 2\n",
    "#     ax_col = i % 2\n",
    "#     prod[clinic_name].plot(ax=axes[ax_row, ax_col], legend=True)\n",
    "#     axes[ax_row, ax_col].set_title(clinic_name)\n",
    "\n",
    "# # Adjust layout and display the plot\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# num_proc = len(proc.columns)\n",
    "# num_rows = math.ceil(num_proc / 2)  # Use 2 columns per row\n",
    "# fig, axes = plt.subplots(nrows=num_rows, ncols=2, figsize=(18, 3 * num_rows))\n",
    "# for i, proc_name in enumerate(proc.columns):\n",
    "#     ax_row = i // 2\n",
    "#     ax_col = i % 2\n",
    "#     proc[proc_name].plot(ax=axes[ax_row, ax_col], legend=True)\n",
    "#     axes[ax_row, ax_col].set_title(proc_name)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# num_proc = len(proc_returns.columns)\n",
    "# num_rows = math.ceil(num_proc / 2)  # Use 2 columns per row\n",
    "# fig, axes = plt.subplots(nrows=num_rows, ncols=2, figsize=(18, 3 * num_rows))\n",
    "# for i, proc_name in enumerate(proc_returns.columns):\n",
    "#     ax_row = i // 2\n",
    "#     ax_col = i % 2\n",
    "#     proc_returns[proc_name].plot(ax=axes[ax_row, ax_col], legend=True)\n",
    "#     axes[ax_row, ax_col].set_title(proc_name)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# sns.pairplot(pat_returns, kind='reg')\n",
    "\n",
    "# sns.clustermap(prod.corr(), annot=True, cmap='summer', fmt=\".2f\",row_cluster=False, figsize=(15,10))\n",
    "# plt.show()\n",
    "\n",
    "# correlation_matrix = prod.corr()\n",
    "# def generate_correlation_report(correlation_matrix, threshold=0.5):\n",
    "#     report = []\n",
    "#     processed_pairs = set()\n",
    "\n",
    "#     for col1 in correlation_matrix.columns:\n",
    "#         for col2 in correlation_matrix.columns:\n",
    "#             if col1 != col2:\n",
    "#                 if (col1, col2) not in processed_pairs and (col2, col1) not in processed_pairs:\n",
    "#                     correlation = correlation_matrix.loc[col1, col2]\n",
    "#                     if abs(correlation) >= threshold:\n",
    "#                         report.append((col1, col2, correlation))\n",
    "#                     processed_pairs.add((col1, col2))\n",
    "\n",
    "#     if not report:\n",
    "#         report.append((\"No strong correlations found\", \"\", 0.0))\n",
    "\n",
    "#     return report\n",
    "\n",
    "# # Call the function with your correlation matrix\n",
    "# correlation_report = generate_correlation_report(correlation_matrix, threshold=0.7)\n",
    "\n",
    "# # Convert the report list into a DataFrame\n",
    "# df = pd.DataFrame(correlation_report, columns=['Process 1', 'Process 2', 'Correlation Coefficient'])\n",
    "# df\n",
    "\n",
    "# correlation_matrix = proc.corr()\n",
    "\n",
    "# # Define a function to generate a correlation report\n",
    "# def generate_correlation_report(correlation_matrix, threshold=0.5):\n",
    "#     report = []\n",
    "\n",
    "#     for col1 in correlation_matrix.columns:\n",
    "#         for col2 in correlation_matrix.columns:\n",
    "#             if col1 != col2:\n",
    "#                 correlation = correlation_matrix.loc[col1, col2]\n",
    "#                 if abs(correlation) >= threshold:\n",
    "#                     report.append((col1, col2, correlation))\n",
    "\n",
    "#     if not report:\n",
    "#         report.append((\"No strong correlations found\", \"\", 0.0))\n",
    "\n",
    "#     return report\n",
    "\n",
    "# # Call the function with your correlation matrix\n",
    "# correlation_report = generate_correlation_report(correlation_matrix, threshold=0.9)\n",
    "\n",
    "# # Convert the report list into a DataFrame\n",
    "# df = pd.DataFrame(correlation_report, columns=['Column 1', 'Column 2', 'Correlation'])\n",
    "\n",
    "# # Print the DataFrame\n",
    "# df\n",
    "\n",
    "# sns.clustermap(proc.iloc[:, :10].corr(), annot=True, cmap='summer', fmt=\".2f\", \n",
    "#                row_cluster=False, figsize=(15,10))\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(figsize=(25, 15))\n",
    "# plt.subplot(2, 2, 1)\n",
    "# sns.heatmap(provider_returns.iloc[:, :10].corr(), annot=True, cmap='summer')\n",
    "# plt.title('Correlation of provider Productions Returns')\n",
    "# plt.subplot(2, 2, 2)\n",
    "# sns.heatmap(provider.iloc[:, :10].corr(), annot=True, cmap='summer')\n",
    "# plt.title('Correlation of provider Productions')\n",
    "\n",
    "# ma_periods = [10, 20, 30]\n",
    "# ma_df = pd.DataFrame()  # Create a new DataFrame for moving averages\n",
    "\n",
    "# for column in proc.columns:\n",
    "#     for period in ma_periods:\n",
    "#         ma_column = f'{column}_MA_{period}'\n",
    "#         ma_df[ma_column] = proc[column].rolling(window=period).mean()\n",
    "\n",
    "# # Plot the original data along with the moving averages\n",
    "# num_proc = len(proc.columns)\n",
    "# num_rows = math.ceil(num_proc / 2)  # Use 2 columns per row\n",
    "# fig, axes = plt.subplots(nrows=num_rows, ncols=2, figsize=(18, 3 * num_rows))\n",
    "# for i, column in enumerate(proc.columns):\n",
    "#     ax_row = i // 2\n",
    "#     ax_col = i % 2\n",
    "#     proc[column].plot(ax=axes[ax_row, ax_col], legend=True, label='Original')\n",
    "#     axes[ax_row, ax_col].set_title(column)\n",
    "#     for period in ma_periods:\n",
    "#         ma_column = f'{column}_MA_{period}'\n",
    "#         ma_df[ma_column].plot(ax=axes[ax_row, ax_col], legend=True, label=f'{period}-period MA')\n",
    "#     axes[ax_row, ax_col].legend()\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# data.drop('Clinic_Name', axis = 1, inplace = True)\n",
    "\n",
    "# summary_period = 24     # 12 months\n",
    "# ref_mean = np.mean(train[-summary_period:].values)\n",
    "# ref_std = np.std(train[:-summary_period].values)\n",
    "\n",
    "# one_std_bands = (ref_mean - ref_std, ref_mean + ref_std)\n",
    "# two_std_bands = (ref_mean - (2 * ref_std), ref_mean + (2 * ref_std))\n",
    "# three_std_bands = (ref_mean - (3 * ref_std), ref_mean + (3 * ref_std))\n",
    "\n",
    "# ax, fig = plt.subplots(figsize = (15, 5))\n",
    "# plt.plot(train, label = \"Training\", color = '#7b57cb')\n",
    "# plt.plot(test, label = \"Testing\", color = '#009ca6')\n",
    "# plt.axhline(y = one_std_bands[0], color = \"#262626\", linestyle = \"dotted\", label = \"1 s.d.\")\n",
    "# plt.axhline(y = one_std_bands[1], color = \"#262626\", linestyle = \"dotted\")\n",
    "# plt.axhline(y = two_std_bands[0], color = \"#FF8A3D\", linestyle = \"dotted\", label = \"2 s.d.\")\n",
    "# plt.axhline(y = two_std_bands[1], color = \"#FF8A3D\", linestyle = \"dotted\")\n",
    "# plt.axhline(y = three_std_bands[0], color = \"#D62598\", linestyle = \"dotted\", label = \"3 s.d.\")\n",
    "# plt.axhline(y = three_std_bands[1], color = \"#D62598\", linestyle = \"dotted\")\n",
    "# plt.legend(loc = 'best', fontsize = (13))\n",
    "# plt.xlabel(\"Date\", fontsize = (20))\n",
    "# plt.ylabel(\"Production Balance\", fontsize = (20))\n",
    "# plt.title(\"Forecasting Production\", fontsize = 20)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05518a23",
   "metadata": {},
   "source": [
    "## Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e757ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.resample('W').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f563553b",
   "metadata": {},
   "source": [
    "### Time series Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359be473",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[:-(5 * 12)]\n",
    "test = data[-(5 * 12):]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d79c78f",
   "metadata": {},
   "source": [
    "### Normal Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfce8300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = data[:int(len(data) * 0.8)]\n",
    "# test = data[int(len(data) * 0.8):]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453cd3dc",
   "metadata": {},
   "source": [
    "# ETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fc9c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Daily \n",
    "model_daily = ExponentialSmoothing(train, trend='mul', seasonal='add', seasonal_periods=84).fit()\n",
    "forecast_daily = model_daily.forecast(steps=365)\n",
    "\n",
    "# Weekly Forecast\n",
    "model_weekly = ExponentialSmoothing(train, trend='mul', seasonal='mul', seasonal_periods=32).fit()\n",
    "forecast_weekly = model_weekly.forecast(steps=48)\n",
    "\n",
    "# Monthly Forecast\n",
    "model_monthly = ExponentialSmoothing(train.resample('M').mean(),trend='mul',seasonal='mul',seasonal_periods=12).fit()\n",
    "forecast_monthly = model_monthly.forecast(steps=12)\n",
    "\n",
    "# Create the forecast indices for weekly, monthly, and daily forecasts\n",
    "forecast_index_weekly = pd.date_range(start=test.index[-1], periods=48, freq='W')\n",
    "forecast_index_monthly = pd.date_range(start=test.index[-1], periods=12, freq='M')\n",
    "forecast_index_daily = pd.date_range(start=test.index[-1], periods=365, freq='D')\n",
    "\n",
    "# Filter data for plotting starting from 2021\n",
    "plot_start_date = (test.index[-1] - pd.DateOffset(years=1)).strftime('%Y-%m-%d')\n",
    "training = data[data.index >= plot_start_date]\n",
    "plt.figure(figsize=(25, 6))\n",
    "\n",
    "# Modify the peak detection part to find peaks for both weekly and monthly forecasts\n",
    "peaks_monthly, _ = find_peaks(forecast_monthly)\n",
    "peaks_weekly, _ = find_peaks(forecast_weekly)\n",
    "\n",
    "# Calculate a threshold for labeling only the highest peaks\n",
    "peak_threshold_monthly = 0.70 * max(forecast_monthly)  # Adjust the threshold as needed\n",
    "peak_threshold_weekly = 0.80 * max(forecast_weekly)  # Adjust the threshold as needed\n",
    "\n",
    "# Filter the peaks to select only the highest ones\n",
    "highest_peaks_monthly = [p for p in peaks_monthly if forecast_monthly[p] >= peak_threshold_monthly]\n",
    "highest_peaks_weekly = [p for p in peaks_weekly if forecast_weekly[p] >= peak_threshold_weekly]\n",
    "\n",
    "label_distance = 20  # Distance above the peaks to place labels\n",
    "\n",
    "def format_label(value):\n",
    "    if value >= 1000:\n",
    "        return f'{int(round(value / 1000))}k'\n",
    "    return f'{int(round(value))}'\n",
    "\n",
    "for peak in highest_peaks_monthly:\n",
    "    forecast_value = forecast_monthly[peak]\n",
    "    label = f'{format_label(forecast_value)}'\n",
    "    plt.annotate(label, (forecast_index_monthly[peak], forecast_value + label_distance),\n",
    "                 textcoords=\"offset points\", xytext=(0, 0), ha='center', fontsize=15,\n",
    "                 bbox=dict(boxstyle='round,pad=0.3', facecolor='white'))\n",
    "\n",
    "for peak in highest_peaks_weekly:\n",
    "    forecast_value = forecast_weekly[peak]\n",
    "    label = f'{format_label(forecast_value)}'\n",
    "    plt.annotate(label, (forecast_index_weekly[peak], forecast_value + label_distance),\n",
    "                 textcoords=\"offset points\", xytext=(0, 0), ha='center', fontsize=15,\n",
    "                 bbox=dict(boxstyle='round,pad=0.3', facecolor='white'))\n",
    "    \n",
    "plt.plot(training.index, training, test.index, test, color='skyBlue', linewidth=4)\n",
    "plt.plot(forecast_index_weekly, forecast_weekly, label='Weekly Forecast', color='lightgreen', linewidth=6)\n",
    "plt.plot(forecast_index_monthly, forecast_monthly, label='Monthly Forecast', color='gold', linewidth=6)\n",
    "plt.plot(forecast_index_daily, forecast_daily, label='daily Forecast', color='darkgrey', linewidth=2)\n",
    "plt.legend(loc='best')\n",
    "plt.title('Multi-Frequency Forecast')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "\n",
    "# Set the major ticks on the x-axis at weekly intervals\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_locator(WeekdayLocator(byweekday=0, interval=5))\n",
    "ax.xaxis.set_major_formatter(DateFormatter(\"%Y-%m\"))\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2eab42c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fit an auto-ETS model\n",
    "model = ExponentialSmoothing(train, trend='mul', seasonal='mul', seasonal_periods=32).fit()\n",
    "forecast = model.forecast(steps=12)\n",
    "\n",
    "# Create the forecast index\n",
    "forecast_index = pd.date_range(start=test.index[-1], periods=12, freq='W')\n",
    "plot_start_date = (test.index[-1] - pd.DateOffset(years=1)).strftime('%Y-%m-%d')\n",
    "training = data[data.index >= plot_start_date]\n",
    "peaks, _ = find_peaks(forecast)\n",
    "\n",
    "# Calculate a threshold for labeling only the highest peaks\n",
    "peak_threshold = 0.5 * max(forecast)  # Adjust the threshold as needed\n",
    "\n",
    "# Filter the peaks to select only the highest ones\n",
    "highest_peaks = [p for p in peaks if forecast[p] >= peak_threshold]\n",
    "\n",
    "label_distance = 20  # Distance above the peaks to place labels\n",
    "forecast_index = forecast_index[:len(forecast)]\n",
    "\n",
    "# Calculate prediction intervals manually\n",
    "forecast_stderr = model.sse / (len(train) - 2)\n",
    "z = 1.96  # 95% prediction interval (adjust as needed)\n",
    "lower_bound = forecast - z * np.sqrt(forecast_stderr)\n",
    "upper_bound = forecast + z * np.sqrt(forecast_stderr)\n",
    "\n",
    "plt.figure(figsize=(16, 5))\n",
    "\n",
    "def format_label(value):\n",
    "    if value >= 1000000:\n",
    "        return f'{value / 1000000:.2f}m'\n",
    "    elif value >= 1000:\n",
    "        return f'{value / 1000:.2f}k'\n",
    "    return f'{value:.2f}'\n",
    "\n",
    "for peak in highest_peaks:\n",
    "    forecast_value = forecast[peak]\n",
    "    label = f'{format_label(forecast_value)}'\n",
    "    plt.annotate(label, (forecast_index[peak], forecast_value + label_distance),\n",
    "                 textcoords=\"offset points\", xytext=(0, 0), ha='center', fontsize=12,\n",
    "                 bbox=dict(boxstyle='round,pad=0.3', facecolor='white'))\n",
    "                 \n",
    "plt.plot(training.index, training, color='skyblue', linewidth=5)\n",
    "plt.plot(test.index, test, color='skyblue')\n",
    "plt.plot(forecast_index, forecast, label='Weekly Forecast', color='lightgreen', linewidth=5)\n",
    "plt.fill_between(forecast_index, lower_bound, upper_bound, color='lightgreen', alpha=0.3, label='95% Prediction Interval')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Date', fontsize = 12)\n",
    "plt.ylabel('Production Value', fontsize = 12)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_locator(WeekdayLocator(byweekday=0, interval=2))\n",
    "ax.xaxis.set_major_formatter(DateFormatter(\"%Y-%W\"))\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a61699",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = dataset.groupby('proc_code')['debit_src'].mean()\n",
    "risk = dataset.groupby('proc_code')['debit_src'].std()\n",
    "\n",
    "# Adjust the size of the points\n",
    "area = np.pi * 20\n",
    "\n",
    "# Create the scatter plot\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.scatter(returns, risk, s=area)\n",
    "plt.xlabel('Expected return (Production)')\n",
    "plt.ylabel('Risk (Standard Deviation)')\n",
    "\n",
    "# Annotate points with clinic IDs\n",
    "for label, x, y in zip(returns.index, returns, risk):\n",
    "    plt.annotate(label, xy=(x, y), xytext=(50, 50), textcoords='offset points', ha='right', va='bottom', \n",
    "                 arrowprops=dict(arrowstyle='-', color='blue', connectionstyle='arc3,rad=-0.3'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8e8e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Series Cross-Validation (Walk-Forward Validation)\n",
    "# Time Series K-Fold Cross-Validation\n",
    "# Rolling Origin Validation\n",
    "# Expanding Window Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12eb0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit an auto-ETS model\n",
    "model = ExponentialSmoothing(train, trend='mul', seasonal='mul', seasonal_periods=32).fit()\n",
    "forecast = model.forecast(steps=12)\n",
    "\n",
    "# Create the forecast index\n",
    "forecast_index = pd.date_range(start=test.index[-1], periods=12, freq='W')\n",
    "plot_start_date = (test.index[-1] - pd.DateOffset(years=1)).strftime('%Y-%m-%d')\n",
    "training = data[data.index >= plot_start_date]\n",
    "peaks, _ = find_peaks(forecast)\n",
    "\n",
    "# Calculate a threshold for labeling only the highest peaks\n",
    "peak_threshold = 0.5 * max(forecast)  # Adjust the threshold as needed\n",
    "\n",
    "# Filter the peaks to select only the highest ones\n",
    "highest_peaks = [p for p in peaks if forecast[p] >= peak_threshold]\n",
    "\n",
    "label_distance = 20  # Distance above the peaks to place labels\n",
    "forecast_index = forecast_index[:len(forecast)]\n",
    "\n",
    "# Calculate prediction intervals manually\n",
    "forecast_stderr = model.sse / (len(train) - 2)\n",
    "z = 1.96  # 95% prediction interval (adjust as needed)\n",
    "lower_bound = forecast - z * np.sqrt(forecast_stderr)\n",
    "upper_bound = forecast + z * np.sqrt(forecast_stderr)\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "def format_label(value):\n",
    "    if value >= 1000000:\n",
    "        return f'{value / 1000000:.2f}m'\n",
    "    elif value >= 1000:\n",
    "        return f'{value / 1000:.2f}k'\n",
    "    return f'{value:.2f}'\n",
    "\n",
    "for peak in highest_peaks:\n",
    "    forecast_value = forecast[peak]\n",
    "    label = f'{format_label(forecast_value)}'\n",
    "    plt.annotate(label, (forecast_index[peak], forecast_value + label_distance),\n",
    "                 textcoords=\"offset points\", xytext=(0, 0), ha='center', fontsize=12,\n",
    "                 bbox=dict(boxstyle='round,pad=0.3', facecolor='white'))\n",
    "\n",
    "# Add data labels to actual values\n",
    "for date, value in training.iterrows():\n",
    "    label = f'{format_label(value[\"debit_src\"])}'\n",
    "    plt.annotate(label, (date, value[\"debit_src\"] + label_distance),\n",
    "                 textcoords=\"offset points\", xytext=(0, 0), ha='center', fontsize=12,\n",
    "                 bbox=dict(boxstyle='round,pad=0.3', facecolor='white'))\n",
    "                 \n",
    "plt.plot(training.index, training, color='skyblue', linewidth=5)\n",
    "plt.plot(test.index, test, color='skyblue')\n",
    "plt.plot(forecast_index, forecast, label='Weekly Forecast', color='lightgreen', linewidth=5)\n",
    "plt.fill_between(forecast_index, lower_bound, upper_bound, color='lightgreen', alpha=0.3, label='95% Prediction Interval')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Date', fontsize = 12)\n",
    "plt.ylabel('Production Value', fontsize = 12)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_locator(WeekdayLocator(byweekday=0, interval=2))\n",
    "ax.xaxis.set_major_formatter(DateFormatter(\"%Y-%W\"))\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8346f960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit an auto-ETS model\n",
    "model = ExponentialSmoothing(train, trend='mul', seasonal='mul', seasonal_periods=32).fit()\n",
    "forecast = model.forecast(steps=12)\n",
    "\n",
    "# Create the forecast index\n",
    "forecast_index = pd.date_range(start=test.index[-1], periods=12, freq='W')\n",
    "plot_start_date = test.index[-1].replace(year=test.index[-1].year - 1)\n",
    "training = data[(data.index >= plot_start_date) & (data.index <= test.index[-1])]\n",
    "\n",
    "peaks, _ = find_peaks(forecast)\n",
    "\n",
    "# Calculate a threshold for labeling only the highest peaks\n",
    "peak_threshold = 0.4 * max(forecast)  # Adjust the threshold as needed\n",
    "\n",
    "# Filter the peaks to select only the highest ones\n",
    "highest_peaks = [p for p in peaks if forecast[p] >= peak_threshold]\n",
    "\n",
    "label_distance = 20  # Distance above the peaks to place labels\n",
    "forecast_index = forecast_index[:len(forecast)]\n",
    "\n",
    "# Calculate prediction intervals manually\n",
    "forecast_stderr = model.sse / (len(train) - 2)\n",
    "z = 1.96  # 95% prediction interval (adjust as needed)\n",
    "lower_bound = forecast - z * np.sqrt(forecast_stderr)\n",
    "upper_bound = forecast + z * np.sqrt(forecast_stderr)\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "def format_label(value):\n",
    "    if value >= 1000000:\n",
    "        return f'{value / 1000000:.2f}m'\n",
    "    elif value >= 1000:\n",
    "        return f'{value / 1000:.2f}k'\n",
    "    return f'{value:.2f}'\n",
    "\n",
    "# Add data labels to forecast values with white background\n",
    "for peak in highest_peaks:\n",
    "    forecast_value = forecast[peak]\n",
    "    label = f'{format_label(forecast_value)}'\n",
    "    plt.annotate(label, (forecast_index[peak], forecast_value + label_distance),\n",
    "                 textcoords=\"offset points\", xytext=(0, 0), ha='center', fontsize=12,\n",
    "                 bbox=dict(boxstyle='round,pad=0.3', facecolor='white'))\n",
    "\n",
    "# Add data labels to actual values (every 3rd data point) with white background\n",
    "for i, (date, value) in enumerate(training.iterrows()):\n",
    "    if i % 4 == 0:  # Label every 3rd data point\n",
    "        label = f'{format_label(value[\"debit_src\"])}'\n",
    "        plt.annotate(label, (date, value[\"debit_src\"] + label_distance),\n",
    "                     textcoords=\"offset points\", xytext=(0, 0), ha='center', fontsize=12,\n",
    "                     bbox=dict(boxstyle='round,pad=0.3', facecolor='white'))\n",
    "\n",
    "plt.plot(training.index, training, color='skyblue', linewidth=5)\n",
    "plt.plot(test.index, test, color='skyblue')\n",
    "plt.plot(forecast_index, forecast, label='Weekly Forecast', color='lightgreen', linewidth=5)\n",
    "plt.fill_between(forecast_index, lower_bound, upper_bound, color='lightgreen', alpha=0.3, label='95% Prediction Interval')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Production Value', fontsize=12)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_locator(WeekdayLocator(byweekday=0, interval=2))\n",
    "ax.xaxis.set_major_formatter(DateFormatter(\"%Y-%W\"))\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be72e9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c0b935",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
